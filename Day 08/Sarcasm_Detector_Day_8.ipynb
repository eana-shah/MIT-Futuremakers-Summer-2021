{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d09fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM,Dropout,Bidirectional,GRU\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8aefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39edf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['article_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdef56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d1327",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df653f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "def clean_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "df['headline']=df['headline'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20)) # Text that is Not Sarcastic\n",
    "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(df[df.is_sarcastic == 0].headline))\n",
    "plt.imshow(wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20)) # Text that is Sarcastic\n",
    "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(df[df.is_sarcastic == 1].headline))\n",
    "plt.imshow(wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "text_len=df[df['is_sarcastic']==1]['headline'].str.len()\n",
    "ax1.hist(text_len,color='red')\n",
    "ax1.set_title('Sarcastic text')\n",
    "text_len=df[df['is_sarcastic']==0]['headline'].str.len()\n",
    "ax2.hist(text_len,color='green')\n",
    "ax2.set_title('Not Sarcastic text')\n",
    "fig.suptitle('Characters in texts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "text_len=df[df['is_sarcastic']==1]['headline'].str.split().map(lambda x: len(x))\n",
    "ax1.hist(text_len,color='red')\n",
    "ax1.set_title('Sarcastic text')\n",
    "text_len=df[df['is_sarcastic']==0]['headline'].str.split().map(lambda x: len(x))\n",
    "ax2.hist(text_len,color='green')\n",
    "ax2.set_title('Not Sarcastic text')\n",
    "fig.suptitle('Words in texts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(20,10))\n",
    "word=df[df['is_sarcastic']==1]['headline'].str.split().apply(lambda x : [len(i) for i in x])\n",
    "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\n",
    "ax1.set_title('Sarcastic text')\n",
    "word=df[df['is_sarcastic']==0]['headline'].str.split().apply(lambda x : [len(i) for i in x])\n",
    "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\n",
    "ax2.set_title('Not Sarcastic text')\n",
    "fig.suptitle('Average word length in each text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824d6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b99371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4002c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38524a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdd35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afcdb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea60e12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb54546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
